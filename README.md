<<<<<<< HEAD
# Soft Robot Control System Framework

This repository contains the software framework for controlling a soft robot, featuring a graphical user interface (GUI), hardware communication, and predictive kinematic models.

## Project Overview

The system allows users to control a soft robotic platform with pneumatic actuators managed by an ESP32 microcontroller. The Python-based software provides a GUI for various control modes, sensor monitoring, and interaction with the robot via serial communication. Kinematic calculations (both forward and inverse) are handled using pre-trained predictive models.

## Directory Structure

-   `./` (Root Directory)
    -   `ml_main.py`: Main application entry point to launch the GUI and control system.
    -   `dance_controller.py`: Script for interactive keyboard-controlled dance sequences with music.
-   `communication/`: Modules for handling serial communication with the control hardware (ESP32).
    -   `serial_handler.py`: Core serial communication thread for sending and receiving data.
    -   `length_sender.py`: Manages the formatting and sending of length commands to the hardware.
-   `control/`: Contains the high-level processing logic for the platform.
    -   `ml_processor.py`: The main processing unit that takes sensor data, utilizes predictive models for pose and length calculations, and issues commands.
-   `firmware/`: Arduino sketches for the ESP32 microcontroller.
    -   `Dance/`: Firmware for a specific music-synchronized dance routine.
    -   `High_Level_Controller_UpdatedV2/`: The primary firmware for general platform control, handling commands from the Python application and managing low-level hardware interactions.
-   `gui/`: All graphical user interface components, built with PyQt5.
    -   `main_window.py`: Defines the main application window and integrates all widgets.
    -   `widgets/`: Contains various custom widgets used in the GUI (e.g., joystick control, sensor monitoring, connection panel, visualization).
    -   `styles/`: UI styling information, including color palettes.
-   `MLmodels/`: Houses the predictive kinematic models and related utilities.
    -   `ml_kinematics.py`: Defines the `KinematicModel` class, which loads and uses pre-trained models for forward (sensor data to pose) and inverse (desired pose to actuator lengths) kinematic calculations.
    -   This directory typically contains the active model files (e.g., `.joblib`, `.keras`) used by the `KinematicModel` class.
-   `NEW ML Model/`: Scripts and data related to the training and generation of predictive models.
    -   `generate_data.py`: Script for simulating robot behavior and generating synthetic training data.
    -   `train_model3.py`: Script for training the forward and inverse predictive models using the data generated by `generate_data.py`.
    -   This directory also serves as an output location for newly trained models and datasets (e.g., `.csv` files).

## Prerequisites

-   **Software:**
    -   Python 3.x
    -   PyQt5
    -   NumPy
    -   SciPy
    -   TensorFlow
    -   Scikit-learn
    -   Pyserial
    -   Pygame (for `dance_controller.py` and music features in the GUI)
    -   Arduino IDE (for compiling and uploading firmware to the ESP32)
-   **Hardware:**
    -   Soft robot with pneumatic actuators (e.g., 3 channels).
    -   ESP32 microcontroller or compatible.
    -   Appropriate sensors (IMU, potentiometers/length sensors).
    -   Serial communication interface (USB).

## Setup Instructions

1.  **Clone the Repository:**
    ```bash
    git clone <repository_url>
    cd <repository_directory>
    ```

2.  **Install Python Dependencies:**
    It's recommended to use a virtual environment.
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\\Scripts\\activate
    pip install -r requirements.txt
    ```

3.  **Firmware Setup:**
    -   Open the desired firmware sketch (e.g., `firmware/High_Level_Controller_UpdatedV2/High_Level_Controller_UpdatedV2.ino`) in the Arduino IDE.
    -   Ensure you have the ESP32 board support package installed in the Arduino IDE.
    -   Select the correct board (e.g., "ESP32 Dev Module") and the COM port your ESP32 is connected to.
    -   Modify any hardware-specific pin configurations within the `.ino` file if necessary.
    -   Compile and upload the sketch to the ESP32.

## Running the Application

1.  **Navigate to the Root Directory:**
    Ensure your terminal is in the root directory of the project.

2.  **Run the Main Application:**
    ```bash
    python ml_main.py
    ```

3.  **Connect to Hardware:**
    -   The GUI will launch.
    -   Use the "Connection" widget/tab to select the COM port corresponding to your ESP32.
    -   Click "Connect". The status bar should indicate a successful connection.

## Key Features

-   **Graphical User Interface:** Provides a user-friendly interface for platform control and monitoring.
-   **Multiple Control Modes:** Supports various ways to control the platform, including:
    -   Joystick control for real-time manipulation.
    -   Automated dance sequences.
    -   Direct actuator control.
-   **Sensor Visualization:** Displays real-time data from platform sensors.
-   **Predictive Kinematics:** Utilizes pre-trained models for:
    -   **Forward Prediction:** Estimating platform pose from sensor readings.
    -   **Inverse Prediction:** Calculating required actuator lengths for a desired platform pose.
-   **Hardware Communication:** Robust serial communication with the ESP32 controller.

## Working with Predictive Models

The system relies on predictive models for its kinematic calculations. These models are typically stored in the `MLmodels/` or `NEW ML Model/` directories.

-   **Using Existing Models:**
    -   The `MLmodels/ml_kinematics.py` script (specifically the `KinematicModel` class) is responsible for loading the model files. Ensure the file paths and names in its `__init__` method point to the correct `.joblib` and `.keras` files.

-   **Training New Models:**
    1.  **Data Generation:**
        -   The `NEW ML Model/generate_data.py` script can be used to simulate platform behavior and generate datasets for training. You may need to adjust platform geometry parameters within this script to match your hardware.
        -   This script outputs a `.csv` file (e.g., `simulated_datax.csv`).
    2.  **Model Training:**
        -   The `NEW ML Model/train_model3.py` script uses the generated `.csv` data to train predictive models for both forward and inverse kinematics.
        -   This script will save the trained models (e.g., `rf_pose_model.joblib`, `fk_nn_pose_model.keras`, `ik_nn_model.keras`) and associated scaler objects (`fk_scaler.joblib`, `ik_scaler.joblib`) typically within the `NEW ML Model/` directory.
    3.  **Integration:**
        -   After training, copy the relevant model files to the `MLmodels/` directory (or update the paths in `MLmodels/ml_kinematics.py`) to be used by the main application. Ensure the `KinematicModel` class loads the correct files. The current implementation expects models to be in the `NEW ML Model` directory relative to the `MLmodels/ml_kinematics.py` file.

## Notes

-   This framework is designed as a template and may require adjustments for specific soft robot hardware configurations.
-   Pay close attention to COM port selections, firmware pin assignments, and geometric parameters in the data generation scripts to match your setup.
-   Ensure all paths, especially for model loading and data generation, are correctly configured for your environment. 
=======
# SoftRobotics-PyQt5-GUI
Real-time control and visualization GUI using PyQt5
>>>>>>> 99c2c654008a70de31a6617eaac86ab80bd5b0d4
